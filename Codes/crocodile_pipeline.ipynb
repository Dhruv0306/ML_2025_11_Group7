{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a298b7de",
   "metadata": {},
   "source": [
    "# Crocodile Identification Pipeline\n",
    "\n",
    "This notebook implements a pipeline for automated biometric identification of Mugger Crocodiles using UAV images. The pipeline includes:\n",
    "- Feature extraction using SIFT, HOG, LBP, and ORB\n",
    "- Dimensionality reduction using PCA\n",
    "- Multiple model training and evaluation\n",
    "- Visualization of results and model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081e8f09",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9d2622",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from utils import create_directory, parse_voc_xml, crop_image, extract_croc_id_from_filename\n",
    "from feature_extraction import FeatureExtractor\n",
    "from models import CrocodileClassifier\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2431c5de",
   "metadata": {},
   "source": [
    "## Define the CrocodilePipeline Class\n",
    "\n",
    "This class implements the complete pipeline for crocodile identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7bd8633",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CrocodilePipeline:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the crocodile identification pipeline\n",
    "        \"\"\"\n",
    "        # Initialize feature extractor\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        \n",
    "        # Initialize classifier\n",
    "        self.classifier = CrocodileClassifier()\n",
    "        \n",
    "        # Create output directories\n",
    "        self.output_dirs = {\n",
    "            'training': 'cropped/Training',\n",
    "            'test_known': 'cropped/Test/Known',\n",
    "            'test_unknown': 'cropped/Test/Unknown'\n",
    "        }\n",
    "        for dir_path in self.output_dirs.values():\n",
    "            create_directory(dir_path)\n",
    "    \n",
    "    def process_training_data(self, training_dir):\n",
    "        \"\"\"\n",
    "        Process training data: extract bounding boxes and features\n",
    "        \n",
    "        Args:\n",
    "            training_dir (str): Path to training data directory\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (features, labels)\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        labels = []\n",
    "        total_images = 0\n",
    "        processed_folders = 0\n",
    "        \n",
    "        print(\"\\n=== Starting Training Data Processing ===\")\n",
    "        print(f\"Training directory: {training_dir}\")\n",
    "        \n",
    "        # Process each crocodile folder\n",
    "        for croc_dir in os.listdir(training_dir):\n",
    "            croc_path = os.path.join(training_dir, croc_dir)\n",
    "            if not os.path.isdir(croc_path):\n",
    "                continue\n",
    "            \n",
    "            processed_folders += 1\n",
    "            folder_images = 0\n",
    "            \n",
    "            # Check if this folder has already been processed\n",
    "            cropped_dir = os.path.join(self.output_dirs['training'], croc_dir)\n",
    "            if os.path.exists(cropped_dir) and os.path.isdir(cropped_dir):\n",
    "                print(f\"\\n[Folder {processed_folders}] Loading features from processed folder: {croc_dir}\")\n",
    "                # Load features from processed images\n",
    "                for img_file in os.listdir(cropped_dir):\n",
    "                    if not img_file.endswith('.jpg'):\n",
    "                        continue\n",
    "                    \n",
    "                    folder_images += 1\n",
    "                    total_images += 1\n",
    "                    \n",
    "                    # Load cropped image\n",
    "                    img_path = os.path.join(cropped_dir, img_file)\n",
    "                    cropped_img = cv2.imread(img_path)\n",
    "                    \n",
    "                    if cropped_img is None:\n",
    "                        print(f\"  Warning: Could not read image {img_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract features\n",
    "                    try:\n",
    "                        img_features = self.feature_extractor.extract_all_features(cropped_img)\n",
    "                        features.append(img_features)\n",
    "                        labels.append(croc_dir)\n",
    "                    except Exception as e:\n",
    "                        print(f\"  Error extracting features from {img_file}: {str(e)}\")\n",
    "                        continue\n",
    "                \n",
    "                print(f\"  Loaded {folder_images} images from {croc_dir}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n[Folder {processed_folders}] Processing new folder: {croc_dir}...\")\n",
    "            \n",
    "            # Process each image in the folder\n",
    "            for img_file in os.listdir(croc_path):\n",
    "                if not img_file.endswith('.jpg'):\n",
    "                    continue\n",
    "                \n",
    "                folder_images += 1\n",
    "                total_images += 1\n",
    "                \n",
    "                # Get image and XML paths\n",
    "                img_path = os.path.join(croc_path, img_file)\n",
    "                xml_path = os.path.join(croc_path, img_file.replace('.jpg', '.xml'))\n",
    "                \n",
    "                try:\n",
    "                    # Parse bounding box\n",
    "                    bbox = parse_voc_xml(xml_path)\n",
    "                    \n",
    "                    # Crop image\n",
    "                    cropped_img = crop_image(img_path, bbox)\n",
    "                    \n",
    "                    # Save cropped image\n",
    "                    output_path = os.path.join(self.output_dirs['training'], croc_dir, img_file)\n",
    "                    create_directory(os.path.dirname(output_path))\n",
    "                    cv2.imwrite(output_path, cropped_img)\n",
    "                    \n",
    "                    # Extract features\n",
    "                    img_features = self.feature_extractor.extract_all_features(cropped_img)\n",
    "                    \n",
    "                    features.append(img_features)\n",
    "                    labels.append(croc_dir)\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error processing {img_file}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"  Processed {folder_images} images from {croc_dir}\")\n",
    "        \n",
    "        if len(features) == 0:\n",
    "            raise ValueError(\"No features extracted! Check if the dataset directories are correct.\")\n",
    "        \n",
    "        print(\"\\n=== Training Data Processing Summary ===\")\n",
    "        print(f\"Total folders processed: {processed_folders}\")\n",
    "        print(f\"Total images processed: {total_images}\")\n",
    "        print(f\"Total features extracted: {len(features)}\")\n",
    "        print(f\"Feature dimension: {len(features[0])}\")\n",
    "        print(\"=====================================\\n\")\n",
    "            \n",
    "        return np.array(features), np.array(labels)\n",
    "    \n",
    "    def process_test_data(self, test_dir, is_known=True):\n",
    "        \"\"\"\n",
    "        Process test data: crop images and extract features\n",
    "        \n",
    "        Args:\n",
    "            test_dir (str): Path to test data directory\n",
    "            is_known (bool): Whether the test data is for known crocodiles\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (features, labels) if is_known else (features,)\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        labels = [] if is_known else None\n",
    "        total_images = 0\n",
    "        \n",
    "        print(f\"\\n=== Processing {'Known' if is_known else 'Unknown'} Test Data ===\")\n",
    "        print(f\"Test directory: {test_dir}\")\n",
    "        \n",
    "        # Process each image\n",
    "        for img_file in os.listdir(test_dir):\n",
    "            if not img_file.endswith('.jpg'):\n",
    "                continue\n",
    "            \n",
    "            total_images += 1\n",
    "            print(f\"\\nProcessing image {total_images}: {img_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Get image path\n",
    "                img_path = os.path.join(test_dir, img_file)\n",
    "                \n",
    "                # Crop image (center crop for unknown)\n",
    "                cropped_img = crop_image(img_path)\n",
    "                \n",
    "                # Save cropped image\n",
    "                output_dir = self.output_dirs['test_known' if is_known else 'test_unknown']\n",
    "                output_path = os.path.join(output_dir, img_file)\n",
    "                cv2.imwrite(output_path, cropped_img)\n",
    "                \n",
    "                # Extract features\n",
    "                img_features = self.feature_extractor.extract_all_features(cropped_img)\n",
    "                \n",
    "                features.append(img_features)\n",
    "                if is_known:\n",
    "                    labels.append(extract_croc_id_from_filename(img_file))\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {img_file}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        print(\"\\n=== Test Data Processing Summary ===\")\n",
    "        print(f\"Total images processed: {total_images}\")\n",
    "        print(f\"Total features extracted: {len(features)}\")\n",
    "        if len(features) > 0:\n",
    "            print(f\"Feature dimension: {len(features[0])}\")\n",
    "        print(\"=====================================\\n\")\n",
    "        \n",
    "        if is_known:\n",
    "            return np.array(features), np.array(labels)\n",
    "        return np.array(features)\n",
    "    \n",
    "    def run_pipeline(self, training_dir, test_known_dir, test_unknown_dir):\n",
    "        \"\"\"\n",
    "        Run the complete pipeline\n",
    "        \n",
    "        Args:\n",
    "            training_dir (str): Path to training data directory\n",
    "            test_known_dir (str): Path to known test data directory\n",
    "            test_unknown_dir (str): Path to unknown test data directory\n",
    "        \"\"\"\n",
    "        print(\"\\n=== Starting Crocodile Identification Pipeline ===\")\n",
    "        print(f\"Training directory: {training_dir}\")\n",
    "        print(f\"Known test directory: {test_known_dir}\")\n",
    "        print(f\"Unknown test directory: {test_unknown_dir}\")\n",
    "        print(\"=============================================\\n\")\n",
    "        \n",
    "        print(\"Processing training data...\")\n",
    "        X_train, y_train = self.process_training_data(training_dir)\n",
    "        \n",
    "        print(\"\\nTraining and evaluating models...\")\n",
    "        results = self.classifier.train_and_evaluate(X_train, y_train)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\n=== Model Evaluation Results ===\")\n",
    "        for model_name, metrics in results.items():\n",
    "            print(f\"\\n{model_name}:\")\n",
    "            for metric_name, value in metrics.items():\n",
    "                print(f\"{metric_name}: {value:.4f}\")\n",
    "        print(\"==============================\\n\")\n",
    "        \n",
    "        # Generate and save visualizations\n",
    "        print(\"\\nGenerating visualizations...\")\n",
    "        \n",
    "        # Plot model comparison\n",
    "        self.classifier.plot_model_comparison(results)\n",
    "        print(\"Saved model comparison plot\")\n",
    "        \n",
    "        # Plot cross-validation results\n",
    "        self.classifier.plot_cross_validation_results(results)\n",
    "        print(\"Saved cross-validation results plot\")\n",
    "        \n",
    "        # Plot ROC curves\n",
    "        self.classifier.plot_roc_curves(X_train, y_train)\n",
    "        print(\"Saved ROC curves plot\")\n",
    "        \n",
    "        # Plot confusion matrix for training data\n",
    "        y_pred = self.classifier.predict(X_train)[0]\n",
    "        self.classifier.plot_confusion_matrix(y_train, y_pred, np.unique(y_train))\n",
    "        print(\"Saved confusion matrix plot\")\n",
    "        \n",
    "        # Plot feature importance\n",
    "        self.classifier.plot_feature_importance()\n",
    "        print(\"Saved feature importance plot\")\n",
    "        \n",
    "        # Process known test data\n",
    "        print(\"\\nProcessing known test data...\")\n",
    "        X_test_known, y_test_known = self.process_test_data(test_known_dir, is_known=True)\n",
    "        \n",
    "        # Make predictions for known test data\n",
    "        y_pred_known, confidence_known = self.classifier.predict(X_test_known)\n",
    "        \n",
    "        # Plot confidence distribution for known test data\n",
    "        self.classifier.plot_confidence_distribution(confidence_known, y_pred_known)\n",
    "        print(\"Saved confidence distribution plot for known test data\")\n",
    "        \n",
    "        # Print known test results\n",
    "        print(\"\\n=== Known Test Results ===\")\n",
    "        print(f\"Accuracy: {np.mean(y_pred_known == y_test_known):.4f}\")\n",
    "        print(f\"Average Confidence: {np.mean(confidence_known):.4f}\")\n",
    "        print(\"========================\\n\")\n",
    "        \n",
    "        # Process unknown test data\n",
    "        print(\"\\nProcessing unknown test data...\")\n",
    "        X_test_unknown = self.process_test_data(test_unknown_dir, is_known=False)\n",
    "        \n",
    "        # Make predictions for unknown test data\n",
    "        y_pred_unknown, confidence_unknown = self.classifier.predict(X_test_unknown)\n",
    "        \n",
    "        # Plot confidence distribution for unknown test data\n",
    "        self.classifier.plot_confidence_distribution(confidence_unknown, y_pred_unknown, \n",
    "                                                  filename='confidence_distribution_unknown.png')\n",
    "        print(\"Saved confidence distribution plot for unknown test data\")\n",
    "        \n",
    "        # Print unknown test results\n",
    "        print(\"\\n=== Unknown Test Results ===\")\n",
    "        print(f\"Number of Unknown Predictions: {np.sum(y_pred_unknown == 'Unknown')}\")\n",
    "        print(f\"Average Confidence: {np.mean(confidence_unknown):.4f}\")\n",
    "        print(\"==========================\\n\")\n",
    "        \n",
    "        print(\"\\nAll visualizations have been saved to the 'plots' directory.\")\n",
    "        print(\"\\n=== Pipeline Completed Successfully ===\")\n",
    "        \n",
    "        return results, (y_pred_known, confidence_known), (y_pred_unknown, confidence_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b81c59",
   "metadata": {},
   "source": [
    "## Run the Pipeline\n",
    "\n",
    "Now let's initialize and run the pipeline with our dataset directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55cfb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Initializing FeatureExtractor...\n",
      "[DEBUG] Cache directory: feature_cache\n",
      "[DEBUG] Setting up feature caching...\n",
      "[DEBUG] FeatureExtractor initialization complete\n",
      "\n",
      "=== Starting Crocodile Identification Pipeline ===\n",
      "Training directory: dataset/Training\n",
      "Known test directory: dataset/Test/Known\n",
      "Unknown test directory: dataset/Test/Unknown\n",
      "=============================================\n",
      "\n",
      "Processing training data...\n",
      "\n",
      "=== Starting Training Data Processing ===\n",
      "Training directory: dataset/Training\n",
      "\n",
      "[Folder 1] Loading features from processed folder: Croc1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m pipeline = CrocodilePipeline()\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Run pipeline with dataset directories\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m results, known_results, unknown_results = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset/Training\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_known_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset/Test/Known\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_unknown_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset/Test/Unknown\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 204\u001b[39m, in \u001b[36mCrocodilePipeline.run_pipeline\u001b[39m\u001b[34m(self, training_dir, test_known_dir, test_unknown_dir)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=============================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    203\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessing training data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m X_train, y_train = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining and evaluating models...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    207\u001b[39m results = \u001b[38;5;28mself\u001b[39m.classifier.train_and_evaluate(X_train, y_train)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mCrocodilePipeline.process_training_data\u001b[39m\u001b[34m(self, training_dir)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     img_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_all_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcropped_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     features.append(img_features)\n\u001b[32m     72\u001b[39m     labels.append(croc_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\MachineLearning\\ML_2025_11_Group7\\Codes\\feature_extraction.py:95\u001b[39m, in \u001b[36mFeatureExtractor.extract_all_features\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Extract features in parallel\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers=\u001b[32m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m     93\u001b[39m     futures = {\n\u001b[32m     94\u001b[39m         \u001b[33m'\u001b[39m\u001b[33msift\u001b[39m\u001b[33m'\u001b[39m: executor.submit(\u001b[38;5;28mself\u001b[39m.cached_sift, gray),\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mhog\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcached_hog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgray\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     96\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mlbp\u001b[39m\u001b[33m'\u001b[39m: executor.submit(\u001b[38;5;28mself\u001b[39m.cached_lbp, gray),\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33morb\u001b[39m\u001b[33m'\u001b[39m: executor.submit(\u001b[38;5;28mself\u001b[39m.cached_orb, gray)\n\u001b[32m     98\u001b[39m     }\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# Get results\u001b[39;00m\n\u001b[32m    101\u001b[39m     features = {name: future.result() \u001b[38;5;28;01mfor\u001b[39;00m name, future \u001b[38;5;129;01min\u001b[39;00m futures.items()}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:179\u001b[39m, in \u001b[36mThreadPoolExecutor.submit\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m w = _WorkItem(f, fn, args, kwargs)\n\u001b[32m    178\u001b[39m \u001b[38;5;28mself\u001b[39m._work_queue.put(w)\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_adjust_thread_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:202\u001b[39m, in \u001b[36mThreadPoolExecutor._adjust_thread_count\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    195\u001b[39m thread_name = \u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m % (\u001b[38;5;28mself\u001b[39m._thread_name_prefix \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    196\u001b[39m                          num_threads)\n\u001b[32m    197\u001b[39m t = threading.Thread(name=thread_name, target=_worker,\n\u001b[32m    198\u001b[39m                      args=(weakref.ref(\u001b[38;5;28mself\u001b[39m, weakref_cb),\n\u001b[32m    199\u001b[39m                            \u001b[38;5;28mself\u001b[39m._work_queue,\n\u001b[32m    200\u001b[39m                            \u001b[38;5;28mself\u001b[39m._initializer,\n\u001b[32m    201\u001b[39m                            \u001b[38;5;28mself\u001b[39m._initargs))\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[38;5;28mself\u001b[39m._threads.add(t)\n\u001b[32m    204\u001b[39m _threads_queues[t] = \u001b[38;5;28mself\u001b[39m._work_queue\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Python\\Python312\\Lib\\threading.py:999\u001b[39m, in \u001b[36mThread.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    997\u001b[39m         \u001b[38;5;28;01mdel\u001b[39;00m _limbo[\u001b[38;5;28mself\u001b[39m]\n\u001b[32m    998\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_started\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Python\\Python312\\Lib\\threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Python\\Python312\\Lib\\threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = CrocodilePipeline()\n",
    "\n",
    "# Run pipeline with dataset directories\n",
    "results, known_results, unknown_results = pipeline.run_pipeline(\n",
    "    training_dir=\"dataset/Training\",\n",
    "    test_known_dir=\"dataset/Test/Known\",\n",
    "    test_unknown_dir=\"dataset/Test/Unknown\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1063262",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Let's display the plots generated during the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14db82",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def display_plot(plot_name):\n",
    "    \"\"\"Display a plot from the plots directory\"\"\"\n",
    "    plot_path = os.path.join('plots', plot_name)\n",
    "    if os.path.exists(plot_path):\n",
    "        img = mpimg.imread(plot_path)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(plot_name)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Plot {plot_name} not found.\")\n",
    "\n",
    "# Display all generated plots\n",
    "plot_files = [\n",
    "    'model_comparison.png',\n",
    "    'cross_validation_results.png',\n",
    "    'roc_curves.png',\n",
    "    'confusion_matrix.png',\n",
    "    'feature_importance.png',\n",
    "    'confidence_distribution.png',\n",
    "    'confidence_distribution_unknown.png'\n",
    "]\n",
    "\n",
    "for plot_file in plot_files:\n",
    "    print(f\"\\nDisplaying {plot_file}:\")\n",
    "    display_plot(plot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e538d",
   "metadata": {},
   "source": [
    "## Test Individual Images\n",
    "\n",
    "Let's create a function to test the model on individual crocodile images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb568de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_image(image_path):\n",
    "    \"\"\"Test the model on a single image\"\"\"\n",
    "    # Load and display the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not read image: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Convert BGR to RGB for display\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(\"Test Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    try:\n",
    "        # Crop the image\n",
    "        cropped_img = crop_image(image_path)\n",
    "        \n",
    "        # Extract features\n",
    "        features = pipeline.feature_extractor.extract_all_features(cropped_img)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction, confidence = pipeline.classifier.predict(np.array([features]))\n",
    "        \n",
    "        print(f\"Prediction: {prediction[0]}\")\n",
    "        print(f\"Confidence: {confidence[0]:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {str(e)}\")\n",
    "\n",
    "# Test example images\n",
    "print(\"Testing a known crocodile image:\")\n",
    "test_single_image(\"dataset/Test/Known/Croc1_1.jpg\")\n",
    "\n",
    "print(\"\\nTesting an unknown crocodile image:\")\n",
    "test_single_image(\"dataset/Test/Unknown/unknown_1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8005000",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the complete crocodile identification pipeline, including:\n",
    "- Processing and feature extraction from training data\n",
    "- Model training and evaluation\n",
    "- Testing on known and unknown crocodile images\n",
    "- Visualization of results and model performance\n",
    "\n",
    "The pipeline successfully processes UAV images, extracts relevant features, and identifies individual crocodiles with associated confidence scores. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
